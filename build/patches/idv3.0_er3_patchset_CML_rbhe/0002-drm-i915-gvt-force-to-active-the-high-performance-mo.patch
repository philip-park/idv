From ee0c54a64573aaf0e2c310235c825b99af731782 Mon Sep 17 00:00:00 2001
From: Weinan Li <weinan.z.li@intel.com>
Date: Tue, 17 Apr 2018 14:37:26 +0800
Subject: [PATCH 02/24] drm/i915/gvt: force to active the high-performance mode
 during vGPU busy

With the RPS interrupt, KMD can adjust the GPU frequency dynamically for
power saving. It works well in the non-virtualized environment, but there
is more latency imported by VMM and virtual interrupt handler which may
break the RPS policy work model, and GPU works in inefficient mode. Here
we force to active the high-performance mode when detect vgpu is busy until
the GPU runs into idle.

(cherry picked from commit c0fd26d469ba5d29ea4be31cf25003f9e3a058c3)

drm/i915/gvt: refine the active_high_performance_mode code

move the force active high-performance mode logic into one work item to
avoid long time softirq delay and suspicious RCU usage.

(cherry picked from commit f63219399ff3ff4d7be6071cfe09d32faa5a1ba2)

Signed-off-by: Colin Xu <colin.xu@intel.com>
(cherry picked from commit fb6ed8b1becf771ff8a338b1360cfc8e67e828d1)
Signed-off-by: Colin Xu <colin.xu@intel.com>
(cherry picked from commit e1c00c6a269448de062ab73973ac7270b95f00b6)
Signed-off-by: Colin Xu <colin.xu@intel.com>
---
 drivers/gpu/drm/i915/gvt/gvt.h       |  1 +
 drivers/gpu/drm/i915/gvt/scheduler.c | 22 ++++++++++++++++++++++
 2 files changed, 23 insertions(+)

diff --git a/drivers/gpu/drm/i915/gvt/gvt.h b/drivers/gpu/drm/i915/gvt/gvt.h
index b47c6acaf9c0..05cd1969f055 100644
--- a/drivers/gpu/drm/i915/gvt/gvt.h
+++ b/drivers/gpu/drm/i915/gvt/gvt.h
@@ -341,6 +341,7 @@ struct intel_gvt {
 	} engine_mmio_list;
 
 	struct dentry *debugfs_root;
+	struct work_struct active_hp_work;
 };
 
 static inline struct intel_gvt *to_gvt(struct drm_i915_private *i915)
diff --git a/drivers/gpu/drm/i915/gvt/scheduler.c b/drivers/gpu/drm/i915/gvt/scheduler.c
index 058dcd541644..d013b98a2c50 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.c
+++ b/drivers/gpu/drm/i915/gvt/scheduler.c
@@ -40,6 +40,7 @@
 #include "gt/intel_context.h"
 
 #include "i915_drv.h"
+#include "intel_pm.h"
 #include "gvt.h"
 
 #define RING_CTX_OFF(x) \
@@ -223,6 +224,24 @@ static void save_ring_hw_state(struct intel_vgpu *vgpu, int ring_id)
 	vgpu_vreg(vgpu, i915_mmio_reg_offset(reg)) = I915_READ_FW(reg);
 }
 
+static void active_hp_work(struct work_struct *work)
+{
+	struct intel_gvt *gvt =
+		container_of(work, struct intel_gvt, active_hp_work);
+	struct drm_i915_private *dev_priv = gvt->dev_priv;
+
+	gen6_disable_rps_interrupts(dev_priv);
+
+	if (READ_ONCE(dev_priv->gt_pm.rps.cur_freq) !=
+	    READ_ONCE(dev_priv->gt_pm.rps.max_freq)) {
+		struct intel_rps *rps = &dev_priv->gt_pm.rps;
+
+		mutex_lock(&rps->lock);
+		intel_set_rps(dev_priv, dev_priv->gt_pm.rps.max_freq);
+		mutex_unlock(&rps->lock);
+	}
+}
+
 static int shadow_context_status_change(struct notifier_block *nb,
 		unsigned long action, void *data)
 {
@@ -264,6 +283,7 @@ static int shadow_context_status_change(struct notifier_block *nb,
 			gvt_dbg_sched("skip ring %d mmio switch for vgpu%d\n",
 				      ring_id, workload->vgpu->id);
 		spin_unlock_irqrestore(&scheduler->mmio_context_lock, flags);
+		schedule_work(&gvt->active_hp_work);
 		atomic_set(&workload->shadow_ctx_active, 1);
 		break;
 	case INTEL_CONTEXT_SCHEDULE_OUT:
@@ -1134,6 +1154,8 @@ int intel_gvt_init_workload_scheduler(struct intel_gvt *gvt)
 		atomic_notifier_chain_register(&engine->context_status_notifier,
 					&gvt->shadow_ctx_notifier_block[i]);
 	}
+	INIT_WORK(&gvt->active_hp_work, active_hp_work);
+
 	return 0;
 err:
 	intel_gvt_clean_workload_scheduler(gvt);
-- 
2.17.1

